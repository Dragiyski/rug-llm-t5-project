{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f350aaef",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from pathlib import Path\n",
    "import transformers, datasets, pickle, multiprocessing, peft, evaluate, py7zr, functools \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422eb06",
   "metadata": {},
   "source": [
    "Global GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = t.device('cpu')\n",
    "model_run_device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70118e0c",
   "metadata": {},
   "source": [
    "Configure a LoRA mostly the same for all the trainers, with the exception of file name and which training set is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16, \n",
    "    target_modules= ['q', 'v'],  \n",
    "    lora_dropout=0.1,  \n",
    ")\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "lora_model = get_peft_model(base_model, lora_config).to(model_run_device)\n",
    "def trainer_inator(file_name, tokens):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./checkpoints/t5_summarization_lora_{file_name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=1e-4,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        log_level=\"info\",\n",
    "        save_total_limit=1,\n",
    "        overwrite_output_dir=True,\n",
    "        disable_tqdm=False,\n",
    "        use_cpu=False,\n",
    "        fp16=True\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=lora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokens['train'],\n",
    "        eval_dataset=tokens['validation'],\n",
    "        tokenizer=T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    )\n",
    "    trainer.model.to(model_run_device)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636cbb1",
   "metadata": {},
   "source": [
    "Create a blank trainer untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tokens = {\n",
    "    \"train\": [],\n",
    "    \"validation\": []\n",
    "}\n",
    "base_trainer = trainer_inator(\"base\", b_tokens)\n",
    "with open(f\"./models/base_trainer.pickle\", \"wb\") as file:\n",
    "    pickle.dump(base_trainer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef67cc",
   "metadata": {},
   "source": [
    "create models for cnn and samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./preprocessing/cnn_tokens.pickle', \"rb\") as file:\n",
    "    cnn_tokens = pickle.load(file)\n",
    "cnn_trainer = trainer_inator(\"cnn\", cnn_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./preprocessing/samsum_tokens.pickle', \"rb\") as file:\n",
    "    samsum_tokens = pickle.load(file)\n",
    "samsum_trainer = trainer_inator(\"samsum\", samsum_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4206f4d",
   "metadata": {},
   "source": [
    "Train the Models!! (and save them to pickles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.train()\n",
    "with open(f\"./models/cnn_trainer.pickle\", \"wb\") as file:\n",
    "    pickle.dump(cnn_trainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsum_trainer.train()\n",
    "with open(f\"./models/samsum_trainer.pickle\", \"wb\") as file:\n",
    "    pickle.dump(samsum_trainer, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (GPU)",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
